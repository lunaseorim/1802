html_text %>%
gsub("[공유 |회|,]","",.) %>%
as.integer() -> res
if(identical(res,integer(0))){
res<-0
}
return(res)
})
# 포스트 단위로 저장합니다.
tar <- bind_cols(posts,
data.frame(like),
data.frame(comment),
data.frame(share))
View(articles)
View(containers)
View(posts)
View(tar)
posts <- posts[-1,]
View(posts)
posts <- posts[,1]
test <- posts[1,1]
test <- tar[1,1]
test <- tar[2,1]
gsub("#","",posts)
gsub("#","",test)
gsub("\\#{\\d}","",test)
gsub("\\#{\\d*}","",test)
gsub("\\#(\\d*)","",test)
gsub("#(\\d*)","",test)
gsub("#\\s+","",test)
gsub("\\#\\s+","",test)
gsub("#\\w+\\s+","",test)
test1 <- tar[2,1]
test2 <- tar[3,1]
test1 <- gsub("#\\w+\\s+","",test1)
test2 <- gsub("#\\w+\\s+","",test1)
test1 <- gsub("#\\w+\\s+","",test1)
test1 <- gsub("제출됨","",test1)
regmatches(test,gregexpr("\\<.+\\>",test))
regmatches(test1,gregexpr("\\<.+\\>",test1))
unlist(regmatches(test1,gregexpr("\\<.+\\>",test1)))
unlist(regmatches(test1,gregexpr("\\<\\>",test1)))
unlist(regmatches(test1,gregexpr("\\< \\>",test1)))
unlist(regmatches(test1,gregexpr("\\<.+\\>",test1)))
gregexpr("\\<\\>",test1)
regmatches(test1,gregexpr("\\<.+\\>",test1))
gregexpr("\\<.+\\>",test1)
regmatches(test1,gregexpr("\\<직원 미인증\\>",test1))
regmatches(test1,gregexpr("\\<직원 미인증\\>",test1))
unlist(regmatches(test1,gregexpr("\\<직원 인증\\>",test1)))
unlist(regmatches(test1,gregexpr("\\<직원.+인증\\>",test1)))
test1 <- tar[2,1]
test2 <- tar[3,1]
test1 <- gsub("#\\w+\\s+","",test1)
test1 <- gsub("제출됨","",test1)
test2 <- gsub("#\\w+\\s+","",test2)
test2 <- gsub("제출됨","",test2)
unlist(regmatches(test1,gregexpr("\\<직원.+인증\\>",test1)))
unlist(regmatches(test2,gregexpr("\\<직원.+인증\\>",test2)))
unlist(regmatches(test2,gregexpr("\\<직원.인증\\>",test2)))
unlist(regmatches(test1,gregexpr("\\<직원.인증\\>",test1)))
unlist(regmatches(test1,gregexpr("\\<직.+증\\>",test1)))
unlist(regmatches(test1,gregexpr("\\<직.+인증\\>",test1)))
unlist(regmatches(test2,gregexpr("\\<직.+인증\\>",test2)))
unlist(regmatches(test2,gregexpr("\\<직 인증\\>",test2)))
unlist(regmatches(test2,gregexpr("\\<직.+ 인증\\>",test2)))
unlist(regmatches(test1,gregexpr("\\<직.+ 인증\\>",test1)))
unlist(regmatches(test1,gregexpr("\\<직 .+인증\\>",test1)))
unlist(regmatches(test1,gregexpr("\\<직원 .+인증\\>",test1)))
unlist(regmatches(test2,gregexpr("\\<직원 .+인증\\>",test2)))
unlist(regmatches(test2,gregexpr("\\<직원 .+인증\>",test2)))
unlist(regmatches(test2,gregexpr("\\<+\\>",test2)))
unlist(regmatches(test2,gregexpr("\\<.\\>",test2)))
unlist(regmatches(test2,gregexpr("\\< . \\>",test2)))
unlist(regmatches(test2,gregexpr("\\<.+\\>",test2)))
unlist(regmatches(test2,gregexpr("\\<직.+\\증>",test2)))
unlist(regmatches(test2,gregexpr("<.+>",test2)))
unlist(regmatches(test1,gregexpr("<.+>",test1)))
data.frame("post" = test,
"value" = unlist(regmatches(posts,gregexpr("<.+>",posts))) )
A1 <- data.frame("post" = test,
"value" = unlist(regmatches(posts,gregexpr("<.+>",posts))) )
View(A1)
A1 <- data.frame("post" = posts,
"value" = unlist(regmatches(posts,gregexpr("<.+>",posts))) )
A1 <- data.frame("post" = posts,
"value" = unlist(regmatches(posts,gregexpr("<직.+증>",posts))) )
A1 <- data.frame("post" = posts,
"value" = unlist(regmatches(posts,gregexpr("<직.+증>",posts))) )
unlist(regmatches(test1,gregexpr("<직.+증>",test1)))
A1 <- data.frame("post" = posts,
"value" = unlist(regmatches(posts,gregexpr("<직.+증>",posts))))
rm(list = "A1")
A1 <- data.frame("post" = posts,
"value" = unlist(regmatches(posts,gregexpr("<직.+증>",posts))))
unlist(regmatches(test1,gregexpr("<직.+증>",test1)))
View(tar)
A1 <- data.frame("post" = tar$content,
"value" = unlist(regmatches(tar$content,gregexpr("<직.+증>",tar$content))))
write.csv(tar,"commentscollect2.csv" col.names = F)
write.csv(tar,"commentscollect2.csv",col.names = F)
posts <- read.csv("commentscollect2.csv")
View(posts)
posts$content <- gsub("#\\w+\\s+","",posts$content)
posts$content <- gsub("제출됨","",posts$content)
posts$content <- gsub("오전","",posts$content)
posts$content <- gsub("오후","",posts$content)
A1 <- data.frame("post" = tar$content,
"value" = unlist(regmatches(tar$content,gregexpr("<직.+증>",tar$content))))
A1 <- data.frame("post" = posts$content,
"value" = unlist(regmatches(posts$content,gregexpr("<직.+증>",posts$content))))
A1 <- data.frame("post" = posts$content,
"value" = regmatches(posts$content,gregexpr("<직.+증>",posts$content)))
A1 <- data.frame("post" = posts$content,
"value" = regmatches(posts$content,gregexpr("<직.+증>",posts$content)))
regmatches(posts$content,gregexpr("<직.+증>",posts$content))
unlist(regmatches(posts$content,gregexpr("<직.+증>",posts$content)))
regmatches(posts$content,gregexpr("<직.+증>",posts$content)))
regmatches(posts$content,gregexpr("<직.+증>",posts$content))
C1 <- regmatches(posts$content,gregexpr("<직.+증>",posts$content))
View(C1)
C1[[39]] <- '<직원 미인증'
C1[[39]] <- '<직원 미인증>'
C1[[39]]
C1[[85]] <- "<직원 미인증>"
C1[[102]] <- "<직원 미인증>"
C1[[104]] <- "<직원 미인증>"
C1[[105]] <- "<직원 미인증>"
C1[[106]] <- "<직원 미인증>"
C1[[107]] <- "<직원 미인증>"
C1[[108]] <- "<직원 미인증>"
C1[[109]] <- "<직원 미인증>"
C1[[110]] <- "<직원 미인증>"
C1
C1 <- lapply(a, function(C1) if(identical(C1, character(0))) <직원 미인증> else C1)
C1 <- lapply(a, function(C1) if(identical(C1, character(0))) "<직원 미인증>" else C1)
C1 <- lapply(a, function(C1) if(identical(C1, character(0))) "<직원 미인증>" else C1)
C1 <- lapply(C1, function(C1) if(identical(C1, character(0))) "<직원 미인증>" else C1)
A1 <- data.frame("post" = posts$content,
"value" = unlist(C1))
C1 <- regmatches(posts$content,gregexpr("<직.+증>",posts$content))
C1 <- lapply(C1, function(C1) if(identical(C1, character(0))) "<직원 미인증>" else C1)
A1 <- data.frame("post" = posts$content,
"value" = unlist(C1))
A1_Y <- [, == "<직원 인증>"]
A1_Y <- A1[, == "<직원 인증>"]
A1_Y <- A1[,"<직원 인증>"]
A1_Y <- A1[,A1$value == "<직원 인증>"]
A1_Y <- A1[ ,A1$value == "<직원 인증>"]
A1$value == "<직원 인증>"
A1_Y <- A1[A1$value == "<직원 인증>",1]
A1_N <- A1[A1$value == "<직원 미인증>",1]
A1
str(A1_Y)
as.character(A1_Y)
A1_Y <- A1[A1$value == "<직원 인증>", ]
A1_N <- A1[A1$value == "<직원 미인증>", ]
View(A1_N)
View(A1_Y)
View(A1)
write.csv(A1,"commentscollect2.csv",fileEncoding = 'UTF-8')
library(tidyverse)
library(ggplot2)
library(tidytext)
library(KoNLP)
useNIADic()
library(wordcloud2)
library(reshape2)
library(tm)
library(qgraph)
posts <- read.csv("../commentscollect2.csv",
stringsAsFactors = F)
A1 <- read.csv("../commentscollect2.csv",
stringsAsFactors = F)
View(A1)
A1 <- read.csv("../commentscollect2.csv",
View(A1)
A1_Y <- A1[A1$value == "<직원 인증>", ]
A1 <- read.csv("../commentscollect2.csv",
stringsAsFactors = F,
encoding = 'UTF-8')
A1_Y <- A1[A1$value == "<직원 인증>", ]
A1 <- read.csv("../commentscollect2.csv",
stringsAsFactors = F,
encoding = 'UTF-8')
A1 <- read.csv("../commentscollect2.csv",
stringsAsFactors = F)
A1 <- read.csv("../commentscollect2.csv",
stringsAsFactors = F,
encoding = 'UTF-8')
A1 <- read.csv("../commentscollect2.csv",
stringsAsFactors = F)
A1_Y <- A1[A1$value == "<직원 인증>", ]
A1_N <- A1[A1$value == "<직원 미인증>", ]
A1_Y <- A1_Y$post
A1_N <- A1_N$post
gsub("<직.+증>","",A1)
gsub("<직.+증>","",A1$post)
A1$post <- gsub("<직.+증>","",A1$post)
B1 <- A1$post %>%
SimplePos09 %>%
melt %>%
as_tibble %>%
select(3, 1)
View(B1)
B2 <- B1 %>%
mutate(noun=str_match(value, '([??-?R]+)/N')[,2]) %>%
na.omit %>%
filter(str_length(noun)>=2) %>%
count(noun, sort=TRUE)
View(B2)
B2 <- B1 %>%
mutate(noun=str_match(value, '([가-힣]+)/N')[,2]) %>%
na.omit %>%
filter(str_length(noun)>=2) %>%
count(noun, sort=TRUE)
ggplot(A3,aes(x=reorder(noun, -n),y=n)) +
geom_bar(stat = "identity")
ggplot(B2,aes(x=reorder(noun, -n),y=n)) +
geom_bar(stat = "identity")
head(B2,20)
B3 <- head(B2,20)
ggplot(B3,aes(x=reorder(noun, -n),y=n)) +
geom_bar(stat = "identity")
ko_words <- function(doc) {
d <- as.character(doc)
pos <- unlist(SimplePos22(d))
extracted <- str_match(pos, '([??-?R]+)/[NP][A-Z]')
keyword <- extracted[, 2]
keyword[!is.na(keyword)]
}
texts <- A1 %>%
str_replace_all(pattern="\r", replacement="") %>%
str_replace_all(pattern="\n", replacement=" ") %>%
str_replace_all(pattern="[[:punct:]]", replacement=" ") %>%
str_replace_all(pattern="[??-????-??]+", replacement="") %>%
str_replace_all(pattern="/", replacement=" ") %>%
str_trim(side="both")
texts <- texts[texts != ""]
pos <- Map(ko_words, texts)
pos <- Map(ko_words, texts)
corpus <- Corpus(VectorSource(pos))
tdm <- TermDocumentMatrix(corpus, control=list(
removePunctuation=TRUE, stopwords=stopWord,
removeNumbers=TRUE, wordLengths=c(4, 10), weighting=weightBin))
tdm <- TermDocumentMatrix(corpus, control=list(
removePunctuation=TRUE,
removeNumbers=TRUE, wordLengths=c(4, 10), weighting=weightBin))
tdm.matrix <- as.matrix(tdm)
word.count <- rowSums(tdm.matrix)
word.order <- order(word.count, decreasing=TRUE)
freq.words <- tdm.matrix[word.order[1:30], ]
co.matrix <- freq.words %*% t(freq.words)
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=3,
vsize=log(diag(co.matrix)) * 2)
View(tdm)
texts <- A1 %>%
str_replace_all(pattern="\r", replacement="") %>%
str_replace_all(pattern="\n", replacement=" ") %>%
str_replace_all(pattern="[[:punct:]]", replacement=" ") %>%
str_replace_all(pattern="[??-????-??]+", replacement="") %>%
str_replace_all(pattern="/", replacement=" ") %>%
str_trim(side="both")
texts <- texts[texts != ""]
pos <- Map(ko_words, texts)
corpus <- Corpus(VectorSource(pos))
tdm <- TermDocumentMatrix(corpus, control=list(
removePunctuation=TRUE,
removeNumbers=TRUE, wordLengths=c(4, 10), weighting=weightBin))
tdm.matrix <- as.matrix(tdm)
word.count <- rowSums(tdm.matrix)
word.order <- order(word.count, decreasing=TRUE)
freq.words <- tdm.matrix[word.order[1:30], ]
co.matrix <- freq.words %*% t(freq.words)
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=3,
vsize=log(diag(co.matrix)) * 2)
View(co.matrix)
library(tidyverse)
library(ggplot2)
library(tidytext)
library(KoNLP)
useNIADic()
library(wordcloud2)
library(reshape2)
library(tm)
library(qgraph)
wordcloud2(B2[1:30,],fontFamily = '나눔고딕',
minRotation=0, maxRotation=0)
wordcloud2(B2[1:30,],fontFamily = '나눔고딕',
minRotation=0, maxRotation=0)
wordcloud2(B2[1:30,],fontFamily = '나눔고딕',
minRotation=0, maxRotation=0)
ko_words <- function(doc) {
d <- as.character(doc)
pos <- unlist(SimplePos22(d))
extracted <- str_match(pos, '([가-힣]+)/[NP][A-Z]')
keyword <- extracted[, 2]
keyword[!is.na(keyword)]
}
texts <- A1 %>%
str_replace_all(pattern="\r", replacement="") %>%
str_replace_all(pattern="\n", replacement=" ") %>%
str_replace_all(pattern="[[:punct:]]", replacement=" ") %>%
str_replace_all(pattern="[ㄱ-ㅎㅏ-ㅣ]+", replacement="") %>%
str_replace_all(pattern="/", replacement=" ") %>%
str_trim(side="both")
texts <- texts[texts != ""]
pos <- Map(ko_words, texts)
pos <- Map(ko_words, texts)
corpus <- Corpus(VectorSource(pos))
tdm <- TermDocumentMatrix(corpus, control=list(
removePunctuation=TRUE, stopwords=stopWord,
removeNumbers=TRUE, wordLengths=c(4, 10), weighting=weightBin))
stopWord <- c("텍스트", "분석")
tdm <- TermDocumentMatrix(corpus, control=list(
removePunctuation=TRUE, stopwords=stopWord,
removeNumbers=TRUE, wordLengths=c(4, 10), weighting=weightBin))
tdm.matrix <- as.matrix(tdm)
word.count <- rowSums(tdm.matrix)
word.order <- order(word.count, decreasing=TRUE)
freq.words <- tdm.matrix[word.order[1:30], ]
co.matrix <- freq.words %*% t(freq.words)
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=3,
vsize=log(diag(co.matrix)) * 2)
texts <- A1$post %>%
str_replace_all(pattern="\r", replacement="") %>%
str_replace_all(pattern="\n", replacement=" ") %>%
str_replace_all(pattern="[[:punct:]]", replacement=" ") %>%
str_replace_all(pattern="[ㄱ-ㅎㅏ-ㅣ]+", replacement="") %>%
str_replace_all(pattern="/", replacement=" ") %>%
str_trim(side="both")
texts <- texts[texts != ""]
pos <- Map(ko_words, texts)
corpus <- Corpus(VectorSource(pos))
tdm <- TermDocumentMatrix(corpus, control=list(
removePunctuation=TRUE, stopwords=stopWord,
removeNumbers=TRUE, wordLengths=c(4, 10), weighting=weightBin))
tdm.matrix <- as.matrix(tdm)
word.count <- rowSums(tdm.matrix)
word.order <- order(word.count, decreasing=TRUE)
freq.words <- tdm.matrix[word.order[1:30], ]
co.matrix <- freq.words %*% t(freq.words)
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=3,
vsize=log(diag(co.matrix)) * 2)
View(C1)
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=3,
vsize=log(diag(co.matrix)) * 2)
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=3,
vsize=log(diag(co.matrix)) * 1)
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=3,
vsize=log(diag(co.matrix)) * 1.5)
View(co.matrix)
texts
texts <- A1$post %>%
str_replace_all(pattern="\r", replacement="") %>%
str_replace_all(pattern="\n", replacement=" ") %>%
str_replace_all(pattern="[[:punct:]]", replacement=" ") %>%
str_replace_all(pattern="[ㄱ-ㅎㅏ-ㅣ]+", replacement="") %>%
str_replace_all(pattern="/", replacement=" ") %>%
str_trim(side="both")
texts <- texts[texts != ""]
View(pos)
View(tdm.matrix)
View(B1)
B2 <- B1 %>%
mutate(noun=str_match(value, '([가-힣]+)/P')[,2]) %>%
na.omit %>%
filter(str_length(noun)>=2) %>%
count(noun, sort=TRUE)
View(B2)
`명사에 관하여`
AAAA1 <- read.csv("data/1in.csv")
View(AAAA1)
str(AAA1)
str(AAAA1)
AAAA1$전공 <- factor(AAAA1$전공,
levels = c("공학 계열",
"자연과학 계열",
"상경 계열",
"인문사회 계열",
"예체능 계열",
"기타"),
labels = 1:6)
AAAA1 <- read.csv("data/1in.csv")
AAAA1$전공 <- factor(AAAA1$전공,
labels = c("공학 계열",
"자연과학 계열",
"상경 계열",
"인문사회 계열",
"예체능 계열",
"기타"),
levels = 1:6)
library(dplyr)
library(plyr)
ddply(AAAA1,~전공,summarize, 매출평균 = round(mean(매출액),0)
ddply(AAAA1,~전공,summarize, 매출평균 = round(mean(매출액),0))
ddply(AAAA1,~전공,summarize, 매출평균 = round(mean(매출액),0))
AAAA1$전공 <- factor(AAAA1$경력연관성,
labels = c("전혀 연관이 없다",
"연관이 없다",
"보통이다",
"연관이 있다",
"매우 연관이 있다"),
levels = 1:5)
AAAA1$경력연관성 <- factor(AAAA1$경력연관성,
labels = c("전혀 연관이 없다",
"연관이 없다",
"보통이다",
"연관이 있다",
"매우 연관이 있다"),
levels = 1:5)
AAAA1 <- read.csv("data/1in.csv")
AAAA1$경력연관성 <- factor(AAAA1$경력연관성,
labels = c("전혀 연관이 없다",
"연관이 없다",
"보통이다",
"연관이 있다",
"매우 연관이 있다"),
levels = 1:5)
ddply(AAAA1,~경력연관성,summarize, 매출평균 = round(mean(매출액),0))
A1_Y <- gsub("<직.+증>","",A1_Y)
A1_N <- gsub("<직.+증>","",A1_N)
View(B1)
View(freq.words)
freq.words <- tdm.matrix[word.order[1:40], ]
View(freq.words)
freq.words <- tdm.matrix[word.order[1:30], ]
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=3,
vsize=log(diag(co.matrix)) * 1.5,
color = "red")
qgraph(co.matrix, labels=rownames(co.matrix),
diag=FALSE, layout='spring', threshold=3,
vsize=log(diag(co.matrix)) * 1.5)
gregexpr("의원",A1)
View(A1)
AAA1 <- regmatches(A1,gregexpr("의원",A1))
View(AAA1)
View(C1)
View(A1)
View(posts)
AAA1 <- regmatches(posts$content,gregexpr("의원",posts$content))
View(AAA1)
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "없음" else AAA1)
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "없음" else AAA1)
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "없음" else AAA1)
AAA1 <- data.frame("post" = posts$content,
"value" = unlist(AAA1))
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "없음" else AAA1)
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "없음" else AAA1)
AAA1 <- regmatches(posts$content,gregexpr("의원",posts$content))
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "없음" else AAA1)
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "없음" else AAA1)
View(AAAA1)
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "없음" else AAA1)
identical(AAA1,character(0))
View(C1)
identical(AAA1,character(>1))
identical(AAA1,character(1))
identical(AAA1,character(0))
AAA1 <- posts$content
AAA1 <- gsub(""<직.+증>"","",AAA1)
AAA1 <- gsub(""<직.+증>"","",AAA1)
AAA1 <- gsub("<직.+증>","",AAA1)
AAA1 <- regmatches(AAA1,gregexpr("의원",AAA1))
View(AAA1)
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "없음" else AAA1)
AAA1 <- posts$content
AAA1 <- gsub("<직.+증>","",AAA1)
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "없음" else AAA1)
View(AAA1)
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "<없음>" else AAA1)
AAA1 <- regmatches(AAA1,gregexpr("의원",AAA1))
AAA1 <- regmatches(posts$content,gregexpr(,posts$content))
AAA1 <- regmatches(posts$content,gregexpr("의원",posts$content))
View(B3)
View(C1)
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "<없음>" else AAA1)
AAA1 <- regmatches(posts$content,gregexpr(,posts$content))
AAA1 <- posts$content
AAA1 <- lapply(AAA1, function(AAA1) if(identical(AAA1, character(0))) "<없음>" else AAA1)
View(AAA1)
AAA1 <- regmatches(posts$content,gregexpr(,posts$content))
AAA1 <- regmatches(posts$content,gregexpr("의원",posts$content))
AAA1 <- regmatches(posts$content,gregexpr("의원",posts$content))
View(AAA1)
AAA1 <- posts$content
library(tidyverse)
library(ggplot2)
library(tidytext)
library(KoNLP)
useNIADic()
library(wordcloud2)
library(reshape2)
library(tm)
library(qgraph)
B3 <- B1 %>%
mutate(noun=str_match(value, '([가-힣]+)/P')[,2]) %>%
na.omit %>%
filter(str_length(noun)>=2) %>%
B3_2 <- head(B3,20)
wordcloud2(B2[1:30,],fontFamily = '나눔고딕',
minRotation=0, maxRotation=0))
wordcloud2(B2[1:30,],fontFamily = '나눔고딕',
minRotation=0, maxRotation=0)
